{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clickstream Processing\n",
        "\n",
        "Load clickstream JSONs from ADLS & clean fields to match desired output.\n",
        "\n",
        "* Reads JSONs from ADLS\n",
        "* Cleanses fields to match desired schema\n",
        "* Saves to ADLS as Parquet\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "# load data\n",
        "\n",
        "df = spark.read.json(\"abfss://{FILE_SYSTEM_NAME}@{DATA_LAKE_NAME}.dfs.core.windows.net/synapse/workspaces/clickstream/new/\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# clean up fields\n",
        "\n",
        "delimiter ='-----'\n",
        "\n",
        "df_final = df \\\n",
        "    .withColumn('Body', regexp_replace('Body','[^0-9A-Za-z_.]','-')) \\\n",
        "    .withColumn('event_time', from_unixtime(unix_timestamp('EnqueuedTimeUtc', 'MM/dd/yyy hh:mm:ss aa'),'yyyy-MM-dd HH:mm:ss.SSS')) \\\n",
        "    .withColumn('event_type', expr('case when Body like \"%ShoppingCart%\" then \"purchase\" else \"view\" end')) \\\n",
        "    .withColumn('product_id', lower(split('Body',delimiter).getItem(5))) \\\n",
        "    .withColumn('category_id',  when(lower(split('Body',delimiter).getItem(11))!=\"\",lower(split('Body',delimiter).getItem(11)))) \\\n",
        "    .withColumn('category_code', when(lower(split('Body',delimiter).getItem(13))!=\"\",lower(split('Body',delimiter).getItem(13)))) \\\n",
        "    .withColumn('brand', when(lower(split('Body',delimiter).getItem(7))!=\"\",lower(split('Body',delimiter).getItem(7)))) \\\n",
        "    .withColumn('price', split('Body',delimiter).getItem(9)) \\\n",
        "    .withColumn('user_session', when(split('Body',delimiter).getItem(15)!=\"\",split('Body',delimiter).getItem(15))) \\\n",
        "    .withColumn('user_id', split('Body',delimiter).getItem(1).cast(IntegerType())) \\\n",
        "    .drop('Body','EnqueuedTimeUtc','Offset','SequenceNumber') \\\n",
        "    .filter(col('product_id').isNotNull())"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "outputs": [],
      "metadata": {},
      "source": [
        "# save to adls\n",
        "\n",
        "df_final.write.mode('append').format('delta').option('header','true').save('abfss://{FILE_SYSTEM_NAME}@{DATA_LAKE_NAME}.dfs.core.windows.net/synapse/workspaces/clickstream/processed/')"
      ],
      "attachments": {}
    }
  ],
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}